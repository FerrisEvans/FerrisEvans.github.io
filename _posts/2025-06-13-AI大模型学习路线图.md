---
title: "AI 大模型学习路线图（尚硅谷）"
date: 2025-06-13
categories: [ai]
tags: []
math: false
mermaid: false
render_with_liquid: false
---

## 1. 前置知识

### 1.1 编程语言

#### 1.1.1 Python

1. 变量、数据类型、控制流语句、函数等
2. Anaconda/Jupyter/PyCharm 等开发环境
3. 编程规范（PEP8）

#### 1.1.2 Java

1. 基础语法：变量、运算符、流程控制
2. 面向对象：类与对象、封装/继承/多态、接口
3. 集合、IO、多线程、Stream

#### 1.1.3 其他编程语言

- Go
- C#
- JavaScript

### 1.2 数学基础

1. 高等数学：导数、偏导、梯度
2. 线性代数：标量与向量、矩阵与张量、矩阵求导
3. 概率统计：概率分布、贝叶斯定理、似然函数

## 2. 大模型应用基础

### 2.1 基础认知

1. AI 与大模型的发展历程
   1. 从机器学习到深度学习的飞跃
   2. 深度学习的诞生与发展
2. 大模型与通用人工智能
   1. 大模型的起源与发展
   2. 认知与解析、大模型与 AGI 的关系、发展趋势

### 2.2 AI 应用场景

1. 自然语言处理 NLP
   1. 分词、词性标注、命名实体识别等 NLP 基础概念
   2. 机器翻译、文本分类、问答系统
2. 计算机视觉 CV
   1. 熟悉图像分类、目标检测、语意分割等 CV 基本概念
   2. 图像识别、视频分析
3. 语音识别与合成
   1. 语音到文本、文本到语音

### 2.3 主流大模型的使用

1. 国际知名
   1. Meta：Llama系列
   2. OpenAI：GPT系列
   3. Google：Gemini系列
   4. Anthropic：Claude系列
2. 国产主流
   1. 深度求索：DeepSeek
   2. 阿里：QWen系列
   3. 百度：文心大模型
   4. 智普清言：GLM系列
   5. 字节跳动：豆包系列
3. 主流大模型平台的功能特点、优势与适用场景
4. 大模型的发展历程、关键推动因素与趋势

### 2.4 架构原理

1. Transformer 架构讲解与动手实现
   1. 编码器 - 解码器结构
   2. 自注意力机制与多头注意力机制
   3. 大模型如何理解和表示单词
   4. 大模型如何理解并预测输入的内容
2. Transformer 变体之 Bert 架构
   1. 使用上文与下文的双向预测模式，类似于填空
3. Transformer 变体之 GPT 架构
   1. 使用从前到后的单向预测模式，类似于补全
4. MoE 模型
   1. MoE 模型的工作原理
   2. MoE 模型的优点
   3. MoE 模型的应用
      1. 自然语言处理
      2. 计算机视觉
      3. 推荐系统

### 2.5 硬件基础

1. GPU 加速原理
   1. GPU 与 CPU 计算核心的区别对比
   2. CUDA 核心/显存管理
2. 混合精度训练：FP16/FP32混合使用

### 2.6 提示词工程

#### 2.6.1 提示词工程基础

1. Prompt 基本概念、在大模型应用中的重要性
2. Prompt 四要素：角色、目标、执行方案、输出格式
3. Prompt 设计的基本规则：简洁性、上下文与语境的设计、问题明确性、结构化与非结构化 Prompt
4. Prompt 调优与技巧
   1. 常见的 Prompt 工程设计策略
      1. 零样本提示 Zero-Shot
      2. 少样本提示 Few-Shot
      3. 链式思考 思维链COT
      4. 自我一致性、自洽性 Self-Consistency
      5. 思维树 Tree-of-thought, ToT
   2. 优化 Prompt 的输出结果
      1. 调整 Prompt 中的语句顺序
      2. 指令和示例的数量与多样性
      3. 负面提示与约束
      4. 增强输出的精确度

#### 2.6.2 高级 Prompt工程技巧

1. 指令模型 vs 推理模型的 Prompt 的不同设计
2. 复杂任务的多步骤 Prompt 设计
3. 解构提示词对 AI 大模型反馈结果的影响
4. 用 Prompt 调优 Prompt
5. Prompt 的攻击与防范
   1. 提示词注入
   2. 提示词防范
   
### 2.6.3 项目实战

1. 短剧脚本生成
2. 网络爆款文案生成
3. 数据库查询 SQL 语句生成
4. 文本生成任务的 Prompt 设计，如编写文章、故事生成
5. 情感分析与文本分类的 Prompt 优化
6. 复杂任务的多步骤 Prompt 设计，如数据分析报告生成

## 3. 大模型应用实战之主流开发框架

### 3.1 LangChain

#### 3.1.1 简介

1. 构建大模型应用的完整流程：大模型交互、数据整合、应用部署
2. 安装
3. 调用大模型三要素：base_url/api_key/model_name

#### 3.1.2 核心组件

1. 模型 IO 操作
   1. 几种不同的 Message
   2. invoke; stream; batch; ainoke
   3. Prompt Template
   4. Output Parsers
   5. Function Calling
2. 链架构 Chains / LCEL
   1. Chains 的设计理念
   2. 传统的 Chain
   3. SequentialChain
   4. RouterChain
   5. Chains 功能实战
3. Memory 记忆功能
   1. 不借助 LangChain 如何实现记忆功能
   2. Memory 模块的设计理念
   3. 如何自定义 Memory 模块
   4. spacy 工具安装
   5. 内置的 Memory 模块
4. 智能体 Agent
   1. Agent 架构设计理念的背景
   2. 基于 LangChain 的 Agent 抽象
   3. 自定义基于 ReAct 范式的 Agent
   4. 使用 LangChain 定义的 ReAct 策略
5. Retrieval
   1. RAG 架构
   2. Source 与 data loaders
   3. Text Splitters
   4. Text embedding models
   5. vector store

#### 3.1.3 项目实战

1. LangChain 构建智能问答系统
2. LangChain 实现文档摘要生成
3. LangChain 实现 AI 销售助手

### 3.2 LangChain4J

#### 3.2.1 简介

1. 定位
2. 核心特性：低代码API、内存优化、本地模型支持
3. 安装
   
#### 3.2.2 核心组件

1. 基础架构
   1. LLM接口：支持 OpenAI、DeepSeek、ZhiPu AI、Anthropic
   2. 内存管理：维护对话上下文（Memory），支持短期/长期记忆
   3. 提示模版：动态生成 Prompt（PromptTemplate），支持变量替换和格式控制
   4. 链（Chain）：串联多个组件（如 LLM + 数据库查询）实现复杂逻辑
   5. 智能体（Agent）：根据用户输入动态选择工具（API/数据库）执行任务
2. 聊天与语言模型
   1. LLM API 类型：LanguageModel, ChatLanguageModel
   2. ChatLanguageModel 核心方法
   3. 消息类型：UserMessage, AiMessage, SystemMessage, ToolExecutionRusltMessage, CustomMessage
3. ChatMemory 组件
   1. 作用：消息管理、持久化存储、特殊消息处理
   2. 核心实现与特性
4. AI Service 的使用
   1. 定位与优势
   2. 注解支持：`@SystemMessage`, `@UserMessage`
5. RAG
   1. 什么是 RAG
   2. 核心流程：索引阶段、检索阶段
   3. 类型：EasyRAG, NaiveRAG, AdvancedRAG
   4. 核心 API 与组件：Document, Metadata, Document Loader, Embedding Model

#### 3.2.3 项目实战

1. 本地知识库问答系统 RAG + ChromaDB
2. 自动化报表分析（代理 + 表格工具）
3. 多模态 AI 助手，集成 TTS/OCR

### 3.3 SpringAI & SpringAI Alibaba

#### 3.3.1 核心组件

1. 模型交互 Model I/O
   1. 统一接口设计：AiClient 与 AiStreamClient
   2. 多模型支持：OpenAI, HuggingFace, 本地模型集成
   3. 提示工程：动态提示模板（PromptTemplate）与输出解析（OutputParser）
2. 数据整合 Retrieval
   1. 向量数据库集成：RedisVectorStore、PgVector
   2. 文档处理链：文本模块（TextSpliter）、嵌入模型（EmbeddingModel）
   3. RAG 实现：检索器（Retriever）与生成器组合
3. 链式执行 Chains
   1. 链式抽象：Chain 接口与 SequentialChain
   2. 路由链 RouterChain：多任务动态路由
   3. 实战：文档总结链、问答链构建
4. 代理 Agents
   1. 代理机制：基于 ReAct 的决策框架
   2. 工具集成：自定义工具，如数据库查询、API调用
   3. 案例：销售顾问代理实现
5. 记忆管理 Memory
   1. 对话状态存储：ChatMemory 接口
   2. 存储后端：Redis、In-Memory 配置

#### 3.3.2 项目实战

1. 基于 Spring AI 的智能客服系统，集成 RAG
2. 文档自动摘要生成，链式调用 + 文本分割
3. 企业级 RAG 问答系统，向量库 + 代理

## 4. 大模型应用实战之 RAG 开发

### 4.1 Embedding Models 嵌入模型

1. 嵌入表示的基本概念与工作原理
2. 常见的嵌入技术
   1. 词嵌入：Word2Vec, GloVe, FastText 等经典方法
   2. 文本嵌入：BERT, GPT 等预训练模型的嵌入
   3. 图像和音频的嵌入表示
   4. 特征嵌入：如何将结构化数据转换为嵌入表示

### 4.2 Vector Store 向量存储

1. 向量数据库介绍
   1. 如何存储和检索嵌入向量
   2. 常见的向量数据库：Milvus, Chroma, Pinecone, FAISS
   3. 向量数据库与传统数据库的区别与优劣对比
2. 向量数据库的核心操作
   1. Add
   2. Query
   3. Update/Delete
3. 使用向量数据库进行相似性检索
4. 向量存储应用
   1. 文本相似度搜索：基于向量的文档匹配
   2. 图像识别与检索：特征向量提取与匹配
   3. 推荐系统：基于用户与物品的向量表示

### 4.3 RAG 工程化

#### 4.3.1 概述

1. LLM 面临的主要问题
   1. 信息偏差/幻觉、知识更新滞后、内容不可溯源
   2. 领域专业知识能力欠缺、长文本处理能力较弱
2. 什么是 RAG
3. 技术优势
   1. 外部知识的利用、生成内容的准确性
   2. 数据及时更新、模型的可解释性
   3. 高度定制能力、减少成本
4. RAG 的核心原理与工作流程解析

#### 4.3.2 应用流程

1. 数据准备阶段
   1. 数据提取
   2. 文本分割
   3. 向量化 Embedding
   4. 数据入库
2. 检索生成阶段
   1. 问题向量化
   2. 数据检索
   3. 注入 Prompt
   4. LLM 生成答案
3. RAG 技术关键环节
   1. 数据检索
   2. Prompt 设计

#### 4.3.3 技术迭代

1. NaiveRAG ➡️ AdvancedRAG ➡️ ModularRAG
2. GraphRAG
   1. 知识图谱
   2. GraphRAG 原理与工作流
3. AgenticRAG

#### 4.3.4 使用效果评估

1. 质量指标
   1. 上下文相关性
   2. 答案忠诚度
   3. 答案相关性
2. 能力指标
   1. 噪声的鲁棒性
   2. 负面信息的排除能力
   3. 面对假设情况的健壮性
3. 评估工具
   1. RAGS
   2. TruLens

#### 4.3.5 RAG 在 AI 对话系统中的应用

1. 使用 RAG 提升对话系统的表现与智能化
2. 结合检索生成的实际案例分析

### 4.4 项目实战

1. QAnything + Chroma + LLM 构建本地私有知识库问答系统
2. Dify + DeepSeek 快速构建企业私有知识库/客服助手
3. RAGFlow + DeepSeek 构建企业级知识库

## 5. 大模型应用实战之 Agent 开发

1. 认识智能体
   1. 智能体的定义与作用
   2. 智能体的基本架构与功能
      1. 规划 Planning
      2. 记忆 Memory
      3. 工具使用 Tools
      4. 执行 Action
2. 工具调用：Fuction Calling
   1. Function Calling 的概念与应用
   2. 跨系统与跨语言的 Function Calling
      1. Function Calling 支持的国产模型介绍
      2. 如何实现不同模型、不同系统间的功能调用
   3. Function Calling 的优化
      1. 提升 Function Calling 的性能与稳定性
      2. 设计高效的 Function Calling 机制
      3. 多 Function Calling 的使用
3. 工作流 Workflow 的搭建与使用
   1. 为什么需要工作流
   2. 大模型应用工作流的关键要素解析
   3. Agently Workflow 的工作流要素
   4. 项目实战
      1. 一键生成学术论文
      2. 一键生成爆款视频
4. Agent 系统
   1. 什么是多 Agent
   2. AutoGen
   3. MetaGPT
   4. Multi-Agent 会话
5. LangGraph
   1. 基础使用
      1. LangChain 与 LangGraph 的区别
      2. LangGraph 对象：图（节点、边、状态）的定义与使用
      3. LangGraph 进阶：检查点（记忆功能）与中断点（手动介入）
      4. LangGraph 工具：搜索引擎
      5. LangGraph 调试：结合 LangSmith 查看 Agent 调用栈
   2. 实践与延展
      1. LangGraph Agent 架构
      2. 基于 LangGraph 构建生产级的 AI Agent
      3. 基于 LangGraph 构建 Multi Agent
   3. 项目实战
      1. 基于 LangGraph 实现多轮对话聊天机器人
      2. 基于 LangGraph 构建 Multi Agent
6. 项目实战
   1. 基于 Dify 快速构建智能体应用
   2. 数据分析助手
   3. 携程 APP 智能体
   4. 基于 LangChain Agent 构建下一代 AI 助手

## 6. 大模型微调

### 6.1 模型微调基础

1. 模型微调的概念
   1. 概念与意义
   2. 微调和 RAG 的关系
   3. 不同场景下微调的必要性
   4. 什么事训练/预训练/微调/轻量化微调
2. 数据工程
   1. 数据采集与清洗
   2. 数据标注与增强
   3. 数据集划分
3. 微调的核心流程
   1. 数据准备与清洗：选择高质量的数据集
   2. 微调技术要点：设置超参数、选择合适的训练方法
   3. 模型评估与验证：确保微调后的模型效果
4. 框架的选择
      1. PyTorch
         1. 张量的创建、索引、运算等操作
         2. 搭建神经网络，定义模型结构、前向传播、反向传播的流程
         3. 案例：基于 PyTorch 的模型构建与训练之手写数字识别
      2. HuggingFace Transformers
      3. unsloth
      4. LLaMA Factory
      5. DeepSpeed

### 6.2 大模型训练

1. 分布式训练
   1. 数据并行与模型并行
   2. 梯度积累与同步
   3. DeepSeed 分布式训练/LLaMA Factory/Xtuner
2. 混合精度训练
   1. FP32 与 FP16 混合使用
   2. 动态损失缩放
3. 模型压缩与加速
   1. 剪枝技术
   2. 量化技术
   3. 知识蒸馏

### 6.3 微调技术与应用

1. 微调策略
   1. 基于预训练模型的微调
   2. 基于特定数据集进行模型微调，包括数据准备、参数设置、训练过程
   3. 解决微调过程中过拟合、训练不收敛等常见问题的方法
2. 轻量化微调技术
   1. Prompt Tuning, P-Tuning, Prefix Tuning
   2. LoRA, QLoRA

### 6.4 大模型微调实战

1. 基于 LoRA 微调 Qwen2 7B
2. 基于 QLoRA 微调 Llama3 8B
3. 基于 QLora 微调 GLM4 9B

### 6.5 HuggingFace 模块开发实战

1. HuggingFace 的安装和开发流程
2. 掌握 HuggingFace 库中各种 API 的调用
3. HuggingFace 工具集：批量编码、Loadding、评价指标，管道等
4. Transformer 加载模型、数据集合预处理

### 6.6 项目实战

1. 动手微调一个 GPT
   1. 模型加载
   2. 数据加载
   3. 训练器
2. 医疗问诊助手
   1. 基础应用：理解并应用大模型的微调与预训练
   2. 核心实操：定制化微调和预训练模型
   3. 优化技巧：提升微调与预训练的效率与效果

### 6.7 DeepSeek 深度解析

1. DeepSeek 的基础架构 MoE 深度解析
2. DeepSeek 核心优势
   1. DeepSeek-V3 的关键技术解析
   2. DeepSeek-R1 的关键技术解析
3. DeepSeek 中的创新点分析
   1. 模型架构
   2. 训练数据优势
4. 通俗理解模型蒸馏技术以及实现原理
   1. 蒸馏模型基本概述
   2. 蒸馏模型的变体与特征
5. 详解 DeepSeek-R1 的四阶段训练流程
   1. 训练目标
   2. 数据处理方式
   3. 模型参数调整策略

## 7. 大模型实战工具

### 7.1 Ollama

1. Ollama 定义与安装
2. 如何调用私有大模型
3. 云端部署（AWS、阿里云）、本地部署等模型部署流程与方法
4. Ollama Java or Python Rest API 与模型对话

### 7.2 Dify AI

1. Dify 定义与搭建
2. Dify 本地部署与服务器部署
3. Dify 工作流构建以及工具调用
4. Dify 导入外部知识库
5. 项目实战
   1. 如何搭建 AI Agent
   2. 搭建智能 AI 客服

### 7.3 Claude

1. 注册和使用
2. Claude 模型与 Claude API Key
3. Claude Function Calling 原理与实现
4. 项目实战：天气查询

### 7.4 Anthropic MCP

1. Function Calling vs MCP
   1. Function Calling 是如何工作的
   2. Function Calling 企业级应用的关注点
   3. 如何使用 Function Calling
2. MCP概念、原理剖析与 C/S 架构
3. 案例：多种 MCP Servers 部署与测试
4. 案例：自定义 MCP

### 7.5 Cursor

1. 使用技巧
2. 调试技巧
3. 快速开发自己的项目

### 7.6 Coze

1. 概述
2. 设置提示词
3. 如何使用工作流
4. 创建自己的插件
5. 添加知识库：文本、表格、图片
6. 创建并使用数据库

### 7.7 AIGC

1. 生成简历，写小红书文案项目
2. Kimi + GPT4 + 文心一言 + Gemini 大模型实操对比
3. 大模型辅导学生做数学题实操项目
4. 小红书创造文案和抖音脚本创作和分镜头实操项目
5. 短篇小说创作爆款微头条项目
6. 大模型进行 AI 画图

## 8. 大模型项目实战

### 8.1 GPT 大型智能翻译助手

1. 大模型企业级方案设计
2. 基于 GPT-4o 大模型 + LangChain 中间件
3. 加载数据模块，AI 模型加载模块，输出数据模块，可视化界面模块等
4. 基于 Gradio 的 Web 界面，支持 PDF、Word、Markdown 等各种文件格式

### 8.2 基于 Transformer 的 NLP 项目

1. Transformer 模型，以及搭建机器翻译系统
2. Encoder - Decoder 架构与缩放点击注意力，实时语音和文字翻译模型

### 8.3 基于 RAG 贝壳网智能客服问答系统

1. GLM4-9B + LangChain 中间件
2. Vector 数据，相似检索
3. 数据 Split 之后通过 Embedding 向量化
4. Gradia 的 UI 界面，FastAPI 接口，uvicorn 服务器

### 8.4 京东客户购买意向预测项目

1. 数据清洗，数据挖掘，数据探索，构建 user 信息
2. 特征工程：数据处理维度，数据基本特征，用户类别，行为特征处理，构建数据集
3. Xsboots建模：数据加载，模型训练， 特征重要性查看，算法预测验证数据，验证数据模型评估，测试数据模型评估

### 8.5 TEXT2SQL + Qwen3 大模型项目实战

1. TEXT2SQL 项目介绍
2. 数据库连接以及 LangChain 自带工具集学习
3. 核心工作流开发：工作流规划 ➡️ 定义异步工作流 ➡️ 异步执行工作流
4. 如何私有化部署最新 QWen3
5. MCP 服务端开发

## 9. 前沿：多模态

### 9.1 多模态理论基础

1. 多模态的最新进展
   1. 模态与多模态的概念
   2. 为什么需要多模态？通往 AGI 的必经之路
2. 多模态技术应用领域
   1. 人机交互
      1. 多模态交互界面设计
      2. 多模态情感计算
   2. 智能安防
      1. 多模态身份认证
      2. 智能视频监控
   3. 医疗健康
      1. 远程医疗咨询
      2. 辅助诊断与治疗
   4. 智能教育
      1. 多模态学习资源
      2. 智能教学系统
3. 大模型与计算机视觉
   1. 安防视觉识别模型原理
   2. 零件缺陷检测模型原理
   3. 医疗诊断识别模型原理
   4. 无人驾驶视觉模型原理
4. 图像生成技术概述
   1. 扩散模型：Diffusion Model
   2. 基于 Diffusion 扩散模型的多模态模型
   3. 稳定扩散模型：StableDiffusion
5. 多模态机器学习与典型任务
   1. 跨模态预训练
   2. Language - Audio/Vision - Audio/Vision - Language
   3. AffectComputing 情感计算
6. 多模态技术未来发展趋势

### 9.2 多模态的微调与优化

1. 多模态模型的微调
   1. 迁移学习
   2. 零样本学习
2. 多模态模型的优化
   1. 剪枝
   2. 量化
   3. 蒸馏
   4. 压缩

### 9.3 多模态模型的部署

1. 本地私有化部署图文描述模型
2. 本地私有化部署文生视频模型
3. 选择模型打包格式
4. 硬件加速方案

### 9.4 项目实战

1. 基于 BLIP 的图生文
2. 基于 StableDiffusion 的文生图
3. 基于 Llama-Vision 的视觉问答
4. 短视频脚本生成（GPT-4o + 多模态提示）
5. 医疗影像报告生成（BLIP + LLM）

## 10. 储备：系统开发

1. 容器化技术：Docker、K8S
2. 云计算平台：AWS、阿里云
3. 微服务架构设计

## 11. 进阶：AI算法

### 11.1 数据分析

1. NumPy
2. Pandas
3. Matplotlib

### 11.2 机器学习

1. 概念与工具
   1. 特征工程
   2. 模型评估、模型选择
2. 监督学习算法
   1. 线性回归
   2. 逻辑回归
   3. KNN 近邻算法
   4. 其他监督学习算法
      1. 朴素贝叶斯
      2. 决策树
      3. 支持向量机
      4. 集成学习
3. 无监督学习
   1. 聚类
      1. K-means
      2. 高斯混合聚类
      3. 密度聚类
      4. 层次聚类
      5. 谱聚类
   2. 降维
      1. 主成分分析
      2. 奇异值分解

### 11.3 深度学习、神经网络与 PyTorch 开发

1. 神经网络基础
   1. 传统机器学习与深度学习的发展
   2. 神经网络的定义和分类
2. 神经网络基本概念
   1. 损失函数
   2. 数值减分
   3. 梯度计算
   4. 随机梯度下降法
3. PyTorch
   1. 安装
   2. 张量
      1. 张量创建与数值计算
      2. 张量类型转换
      3. 张量拼接
      4. 张量索引
      5. 运算函数与自动微分模块
      6. 模型定义与保存加载
   3. 利用 PyTorch 进行深度学习
   4.常见问题分析 
4. 深度学习常见模型：卷积神经网络 CNN
   1. 图像特征提取
   2. 目标检测
5. 深度学习常见模型：循环神经网络 RNN
   1. 实践序列预测
   2. 自然语言处理 NLP

### 11.4 NLP 自然语言处理

1. 概述
   1. 基本概念
   2. 两大核心任务：NLU/NLI、NLG
2. 工作原理
   1. 文本预处理
   2. 特征提取
   3. 文本分析
   4. 模型训练
3. 文本是如何转换为数据的
   1. 语言模型（N-Gram模型）
   2. 分词 Tokenization
   3. Word2Vec 模型
   4. 打造能识别文本情感的模型
4. 详解语言模型与注意力机制
5. 大模型关键技术解析
   1. 预训练
   2. Supervised Fine-Tuning (SFT)
   3. Reinforcement Learning from Human Feedback (RLHF)

### 11.5 算法题